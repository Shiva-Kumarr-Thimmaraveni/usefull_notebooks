{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXehpkffW2r/52MO/n7qNz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiva-Kumarr-Thimmaraveni/usefull_notebooks/blob/langchain_series/langchain_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_groq\n",
        "!pip install chromadb\n",
        "!pip install PyPDF2\n",
        "!pip install python-docx\n",
        "!pip install markdown pdfkit\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EaGgQhS2sTUQ",
        "outputId": "8985343e-9dbc-4e21-c2c2-5041d2df4985"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.38)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.4)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.111)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.11.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.2.38)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (0.1.111)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (8.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.0.7)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.112.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.6)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.6.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.19.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.4)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (30.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.38.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.8.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (3.7)\n",
            "Collecting pdfkit\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: pdfkit\n",
            "Successfully installed pdfkit-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install markdown weasyprint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c1kywoV5chCV",
        "outputId": "fd52d297-5a3b-4c61-97da-dc40d2a7bdbf"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (3.7)\n",
            "Collecting weasyprint\n",
            "  Downloading weasyprint-62.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pydyf>=0.10.0 (from weasyprint)\n",
            "  Downloading pydyf-0.11.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.17.0)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.1)\n",
            "Requirement already satisfied: tinycss2>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (1.3.0)\n",
            "Collecting cssselect2>=0.1 (from weasyprint)\n",
            "  Downloading cssselect2-0.7.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting Pyphen>=0.9.1 (from weasyprint)\n",
            "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1.0 in /usr/local/lib/python3.10/dist-packages (from weasyprint) (9.4.0)\n",
            "Requirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (4.53.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->weasyprint) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2>=0.1->weasyprint) (0.5.1)\n",
            "Collecting zopfli>=0.1.4 (from fonttools[woff]>=4.0.0->weasyprint)\n",
            "  Downloading zopfli-0.2.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting brotli>=1.0.1 (from fonttools[woff]>=4.0.0->weasyprint)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->weasyprint) (1.16.0)\n",
            "Downloading weasyprint-62.3-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
            "Downloading pydyf-0.11.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zopfli-0.2.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (848 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m848.9/848.9 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: brotli, zopfli, Pyphen, pydyf, cssselect2, weasyprint\n",
            "Successfully installed Pyphen-0.16.0 brotli-1.1.0 cssselect2-0.7.0 pydyf-0.11.0 weasyprint-62.3 zopfli-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    temperature = 0,\n",
        "    groq_api_key = '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',\n",
        "    model_name=\"llama-3.1-70b-versatile\",\n",
        "\n",
        ")\n",
        "\n",
        "response = llm.invoke('What can you do ?')\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOipX7DxmWYt",
        "outputId": "4b820c26-043a-4b98-cea0-3af1e5bf58ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can be used in a variety of ways, from helping you plan a vacation to creating art. I'm here to assist you in finding the help or information you need. My strengths include answering questions, generating text and images and even just chatting with you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "chroma_client = chromadb.Client()\n",
        "collection = chroma_client.create_collection(name=\"my_collection1\")\n"
      ],
      "metadata": {
        "id": "lRwZbA-4tfnY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection.add(\n",
        "    documents=[\n",
        "        \"India is the place where people will love fruits\",\n",
        "        \"USA is a place where people love money\"\n",
        "    ],\n",
        "    ids=[\"id1\", \"id2\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "6DlynfcUtvEU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = collection.get(ids = ['id1'])\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuUuume-t-Zs",
        "outputId": "3a12db27-7c64-44ae-d7c5-466c0f0bb34e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [],\n",
              " 'documents': [],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents']}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    query_texts=[\"I like india\"], # Chroma will embed this for you\n",
        "    n_results=2 # how many results to return\n",
        ")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ZRLXayuSVa",
        "outputId": "fdab76aa-df84-4335-a6f2-c51a50e463db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['id1', 'id2']],\n",
              " 'distances': [[0.9047573804855347, 1.2445108890533447]],\n",
              " 'metadatas': [[None, None]],\n",
              " 'embeddings': None,\n",
              " 'documents': [['India is the place where people will love fruits',\n",
              "   'USA is a place where people love money']],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents', 'distances']}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collection.delete(ids=documents['ids'])\n",
        "collection.get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhlWqkFuvcQB",
        "outputId": "d97d20b5-51ab-4bbd-e39d-fd3afc089249"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Delete of nonexisting embedding ID: id1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Delete of nonexisting embedding ID: id1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['id2'],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [None],\n",
              " 'documents': ['USA is a place where people love money'],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents']}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # Open the PDF file\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "\n",
        "        # Iterate through each page\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            page = reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "pdf_path = 'Thimmaraveni-Shiva.pdf'\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "print(pdf_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kkjjbnSeQz7-",
        "outputId": "25913cea-8190-4644-b5cf-1970167bf1e3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thimmaraveni Shiva\n",
            "Hyderabad, Telangana  500070\n",
            "thimmaraveniishiva@gmail.com\n",
            "+91 80965 14884\n",
            "üöÄ Welcome to my professional journey in the realm of technology! \u0002üåê¬†\n",
            "¬†\n",
            "As a passionate individual in the world of technology, I thrive on leveraging cutting-edge tools and\n",
            "frameworks to create innovative solutions. My skill set encompasses a diverse range, including GCP\n",
            "(Google Cloud Platform), Generative AI, AI/ML, React JS, NodeJS, Postgre SQL, Python, HTML5, CSS3,\n",
            "JavaScript, NPM, Git & GitHub, GitLab, Flask, Prompt Engineering, Vertex AI Language Models, and\n",
            "more.¬†\n",
            "¬†\n",
            "\u0004 Skills Snapshot:¬†\n",
            "¬†\n",
            "\u0002 GCP Google Cloud Platform¬†\n",
            "Generative AI Enthusiast¬†\n",
            "AI/ML Enthusiast¬†\n",
            "‚öõ React JS¬†\n",
            "NodeJS¬†\n",
            "‚ú® Postgre SQL¬†\n",
            "üíª Python¬†\n",
            "Ô∏è HTML5, CSS3, JavaScript¬†\n",
            "\u0007 NPM¬†\n",
            "üêò Git & GitHub, GitLab¬†\n",
            "Ô∏è Flask¬†\n",
            "\t Prompt Engineering¬†\n",
            "üêç Vertex AI Language Models¬†\n",
            "...and the list continues!¬†\n",
            "Ô∏è Projects Completed:¬†\n",
            "¬†\n",
            "Ô∏èJunior Data Engineer | Google Cloud DataFlow:¬†\n",
            "Hands-on experience in managing Google Cloud DataFlow jobs.¬†\n",
            "Proficient in Postgre SQL to PL/SQL script conversions.¬†\n",
            "¬†\n",
            "\u0002Google Developer | Document Analyzing Platform:¬†\n",
            "Successfully completed a Proof of Concept (POC) for a C&S client.¬†\n",
            "Developed a robust Document Analyzing Platform.¬†\n",
            "¬†\n",
            "‚òÅÔ∏èCloud AI Developer | RFP Response Generation Tool:¬†\n",
            "Executed a successful POC for Iron Mountain US client.¬†\n",
            "Created an efficient RFP Response Generation Tool.¬†\n",
            "¬†\n",
            "\u000b Achievements:¬†\n",
            "¬†\n",
            "üöÄ Achieved Generative AI E1 Competency and received swags from GOOGLE.¬†üì¶ Committed to constant improvement, working on enhancing AI skills to bring even more efficiency\n",
            "and energy to my future projects.¬†\n",
            "Let's connect and explore the limitless possibilities at the intersection of technology and creativity! \n",
            "üöÄüåê #TechInnovator #AIEnthusiast #GCPChampion #InnovationMatters\n",
            "Personal Details\n",
            "Date Of Birth: 1998-07-24\n",
            "Employment Eligibility: India\n",
            "Highest Career Level: Experienced\n",
            "Industry: Technology\n",
            "Total years of experience: 2\n",
            "Work Experience\n",
            "Cloud Developer\n",
            "Tata Consultancy Services (TCS)  - Hyderabad, Telangana\n",
            "August 2023 to Present\n",
            "‚Ä¢ \u0002Google Developer | Document Analyzing Platform\n",
            "Successfully completed a Proof of Concept (POC) for a C&S client.\n",
            "Developed a robust Document Analyzing Platform.\n",
            "‚Ä¢ ‚òÅÔ∏èCloud AI Developer | RFP Response Generation Tool:\n",
            "Executed a successful POC for Iron Mountain US client.\n",
            "Created an efficient RFP Response Generation Tool.\n",
            "‚Ä¢ \u000b Achievements:\n",
            "üöÄ Achieved Generative AI E1 Competency and received swags from GOOGLE.\n",
            "üì¶ Committed to constant improvement, working on enhancing AI skills to bring even more efficiency\n",
            "and energy to my future projects.\n",
            "Data Engineer Intern\n",
            "Tata Consultancy Services (TCS)  - Hyderabad, Telangana\n",
            "June 2023 to August 2023\n",
            "Use to check the Data Freshness of Google Cloud Data Flow Jobs Served as Google Developer and worked\n",
            "in refining the logical Scripts and changing it to respective forms\n",
            "Skills: PL/SQL ¬∑ PostgreSQL ¬∑ python ¬∑ vertexai ¬∑ Google Cloud Platform (GCP) ¬∑ Data engineer ¬∑ Cloud data\n",
            "flow ¬∑ Pubsub ¬∑ Extract, Transform, Load (ETL)Education\n",
            "Bachelors in EEE\n",
            "Sri Indu College of Engineering and Technology  - Hyderabad, Telangana\n",
            "June 2018 to June 2021\n",
            "Skills / IT Skills\n",
            "‚Ä¢HTML5 (2 years)\n",
            "‚Ä¢CSS (2 years)\n",
            "‚Ä¢JavaScript (2 years)\n",
            "‚Ä¢Google Cloud Platform (1 year)\n",
            "‚Ä¢Bootstrap (2 years)\n",
            "‚Ä¢tailwind CSS (2 years)\n",
            "‚Ä¢Vite + ReactJS (1 year)\n",
            "‚Ä¢React (1 year)\n",
            "‚Ä¢MySQL (1 year)\n",
            "‚Ä¢PostgreSQL (1 year)\n",
            "‚Ä¢Python (2 years)\n",
            "Languages\n",
            "‚Ä¢English - Intermediate\n",
            "‚Ä¢Hindi - Expert\n",
            "‚Ä¢Telugu - Expert\n",
            "Online Profile\n",
            "https://www.linkedin.com/in/shiva-kumarr-thimmaraveni/\n",
            "Awards / Achievements\n",
            "Google SWAG\n",
            "September 2023\n",
            "Excited to share that I received this awesome Google üåêUSB backpack üåê as swag after completing the\n",
            "Gen AI E1 Competency!\n",
            "Certifications and Licenses\n",
            "Google Cloud Associate Cloud Engineer (ACE)\n",
            "February 2022 to February 2025GCP ACE Certification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    # Load the .docx file\n",
        "    doc = Document(docx_path)\n",
        "\n",
        "    # Extract text from each paragraph\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "\n",
        "    # Join all paragraphs into a single string\n",
        "    return '\\n'.join(full_text)\n",
        "\n",
        "# Example usage\n",
        "docx_path = 'Shiva Resume Latest July 2024.docx'\n",
        "document_text = extract_text_from_docx(docx_path)\n",
        "print(document_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o2ldAANLWtGZ",
        "outputId": "9be046a6-16bf-4df6-9966-1f7005d0c624"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skills\n",
            "\n",
            "Programming Languages: Python (Pandas, NumPy, Matplotlib, Seaborn, ScikitLearn, SciPy, os), Java Script\n",
            "Machine Learning: Regression, Classification, Clustering, Association Rule Learning, Reinforcement Learning\n",
            "Deep Learning: ANNs, CNNs, NLP\n",
            "Web Development: HTML5, CSS3, Java Script, Bootstrap, Tailwind CSS, React JS(Basics)\n",
            "Data Visualization: Tableau, Excel, Power BI(Basics)\n",
            "Data Base: PostgreSQL, MySQL\n",
            "Cloud Service Providers: GCP ACE (Google Certified Associate Cloud Engineer) \n",
            "Work Experience\n",
            "DEVELOPER ‚Äì CLIENT Avery Dennison ‚Äì INDIA |Hyd (Remote)\tJUNE 2023 ‚Äì JULY 2024\n",
            "Developed End to End Enterprise Chat Bot using GCP Chat Bison Generative AI Language Model (POC).\n",
            "Development of the whole Code happened in GCP Cloud Shell Editor, Deployed the Application in Google Cloud Run. \n",
            "Used Cloud Storage Bucket for storing User Files, Used Big query for Storing the Chat History.\n",
            "Used Vector Data Base for getting Relevant Answer, Used Prompt Engineering for getting Relevant Answer from LLM Model.\n",
            "Created End to End CI/CD Pipeline using GitHub.\n",
            "Google Developer ‚Äì CLIENT C&S   ‚Äì INDIA |Hyd (Remote)\tJULY 2022 - DECEMBER 2022\n",
            "Developed End to End Application Document Analyzer Suite and deployed in Cloud Run.(POC)\n",
            "Given Functionality for reading PDF Files, Word Documents, csv Files and able to ask questions on top of that using GCP Bison Models the answer will be shared on UI and Developed Complete UI on HTML, CSS & Java Script used Bootstrap for Responsiveness. \n",
            "Worked on SONY Use Case for getting the video clips count in a single uploaded video with time stamps and seek.     JAN 2023\n",
            "Projects\n",
            "BCG DATA SCIENCE JOB SIMULATION ON FORAGE -  Certificate  INDIA |Hyd (Remote)                                                                 July 2024\n",
            "Completed a customer churn analysis simulation for Power Co. demonstrating advanced data analytics skills, identifying essential client data and outlining a strategic investigation approach.\n",
            "Conducted efficient data analysis using Python, including Pandas and NumPy. Employed data visualization techniques for insightful trend interpretation.\n",
            "Completed the engineering and optimization of a random forest model, achieving an 85% accuracy rate in predicting customer churn.\n",
            "Completed a concise executive summary for the Associate Director, delivering actionable insights for informed decision-making based on the analysis.\n",
            "Salary prediction on Given Experinece ‚Äì Personal Project ‚Äì INDIA |Hyd (Remote)                              \tFebruary 2024\n",
            "Used Linear Regression Model for Predicting the Salary of an Employee according to the given Number of years‚Äô Experience.\n",
            "Deployed the application in stream lit and shared the public URL in GitHub\n",
            "Profit Estimation of Startup on GIVEN SPENDS ‚Äì Personal Project ‚Äì INDIA |Hyd (Remote)    \tMarch 2024\n",
            "Estimated Profit by Developing Multi Linear Regression on public Data Set & Deployed in Stream Lit & Shared URL in GitHub\t\n",
            "Education\n",
            "Bachelor of TECHNOLOGY ‚Äì SRI INDU INSTITUATIONS (Affiliated to Jawaharlal Nehru Technological University)\tJune 2021\n",
            "Majors: Electrical & Electronics Engineering \n",
            "Diploma in Computer Applications (DCA)                                                                                                                                                 June 2015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "personal_data = \"\"\"\n",
        "Name : Shiva Kumarr Thimmaraveni,\n",
        "Age : 25,\n",
        "Date_of_birth : July-24th-1998,\n",
        "LinkedIn Profile : https://www.linkedin.com/feed/\n",
        "Git-hub URL : https://github.com/Shiva-Kumarr-Thimmaraveni\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fbuU6YcYdj5y"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targetting_jobs = \"\"\"\n",
        "Data Scientist\n",
        "Data Analyst\n",
        "Business Analyst\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9RFkVxaojrMU"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_extract = PromptTemplate.from_template(\"\"\"\n",
        "### EXTRACTED TEXT FROM PDF\n",
        "{document_text}\n",
        "### PERSONAL DETAILS IF MISSED ANY WHILE EXTRACTING\n",
        "{personal_data}\n",
        "### INSTRUCTION\n",
        "The Extracted Text from the pdf containes the complete Resume of a User,\n",
        "Your job is to Create a Complete Resume on the Existing Skills and Experience,\n",
        "Which can fit in a single page add only relevant information,\n",
        "In a Good Format of adding Markdown Text & needs to be ATS Friendly.\n",
        "Dont add any place holders use personal details if missed any additional information from extracted text.\n",
        "Dont Provide any Notes.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "chain_extract = prompt_extract | llm"
      ],
      "metadata": {
        "id": "gqHw7ZpeT5fX"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recomendations_prompt = PromptTemplate.from_template(\"\"\"\n",
        "### EXTRACTED TEXT FROM PDF\n",
        "{document_text}\n",
        "### PERSONAL DETAILS IF MISSED ANY WHILE EXTRACTING\n",
        "{personal_data}\n",
        "### TARGETING JOB PROFILES\n",
        "{targetting_jobs}\n",
        "### INSTRUCTION\n",
        "The Extracted Text from the pdf containes the complete Resume of a User,\n",
        "The Targetting jobs contain the job profiles in a list,\n",
        "Your job is to Create a Complete Document on the Existing Skills and Experience,\n",
        "Provide with Percentage of chnace for getting a job in all the job profiles in a tabular format,\n",
        "Provide some recommendations on which skills the user can improve.\n",
        "Provide a table of jobs profiles, which are easy to apply from the above skills & Experience.\n",
        "Dont add any place holders use personal details if missed any additional information from extracted text.\n",
        "Dont Provide any Notes.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "recomendations_chain = recomendations_prompt | llm"
      ],
      "metadata": {
        "id": "8-YV7pGrj4yC"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "res = chain_extract.invoke({'document_text': document_text, 'personal_data': personal_data})\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "id": "WeQBfIv8RgLE",
        "outputId": "42df5f7b-bbbc-4cfd-dd4f-92d5737f2d86"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalServerError",
          "evalue": "Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-6f1d2e510a5a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecomendations_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'document_text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocument_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'personal_data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpersonal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'targetting_jobs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargetting_jobs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         return cast(\n\u001b[1;32m    276\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    776\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         flattened_outputs = [\n\u001b[1;32m    636\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 results.append(\n\u001b[0;32m--> 624\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    625\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    847\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_groq/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         }\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    285\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m--> 287\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0;34m\"/openai/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         )\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 936\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    937\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/groq/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mInternalServerError\u001b[0m: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "res2 = recomendations_chain.invoke({'document_text': document_text, 'personal_data': personal_data, 'targetting_jobs': targetting_jobs})\n",
        "print(res2.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgaEwEPGmzlL",
        "outputId": "606f772c-66f9-4442-eb20-e6f6908d5657"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Resume Summary: Shiva Kumarr Thimmaraveni**\n",
            "\n",
            "**Summary:**\n",
            "Shiva Kumarr Thimmaraveni is a 25-year-old Data Science enthusiast with a strong background in Electrical & Electronics Engineering and Computer Applications. He has 2 years of experience in developing end-to-end enterprise applications, chatbots, and data analysis. He has expertise in programming languages such as Python, JavaScript, and has experience with various frameworks and tools like GCP, Tableau, and Power BI.\n",
            "\n",
            "**Technical Skills:**\n",
            "\n",
            "* Programming Languages: Python (Pandas, NumPy, Matplotlib, Seaborn, ScikitLearn, SciPy, os), JavaScript\n",
            "* Machine Learning: Regression, Classification, Clustering, Association Rule Learning, Reinforcement Learning\n",
            "* Deep Learning: ANNs, CNNs, NLP\n",
            "* Web Development: HTML5, CSS3, JavaScript, Bootstrap, Tailwind CSS, React JS (Basics)\n",
            "* Data Visualization: Tableau, Excel, Power BI (Basics)\n",
            "* Database: PostgreSQL, MySQL\n",
            "* Cloud Service Providers: GCP ACE (Google Certified Associate Cloud Engineer)\n",
            "\n",
            "**Professional Experience:**\n",
            "\n",
            "* Developer at Client Avery Dennison - India (Remote) (June 2023 - July 2024)\n",
            "* Google Developer at Client C&S - India (Remote) (July 2022 - December 2022)\n",
            "\n",
            "**Projects:**\n",
            "\n",
            "* BCG Data Science Job Simulation on Forage - Certificate (July 2024)\n",
            "* Salary prediction on Given Experience - Personal Project (February 2024)\n",
            "* Profit Estimation of Startup on Given Spends - Personal Project (March 2024)\n",
            "\n",
            "**Education:**\n",
            "\n",
            "* Bachelor of Technology in Electrical & Electronics Engineering from Sri Indu Institutions (Affiliated to Jawaharlal Nehru Technological University) (June 2021)\n",
            "* Diploma in Computer Applications (DCA) (June 2015)\n",
            "\n",
            "**Job Profile Analysis:**\n",
            "\n",
            "| Job Profile | Chance of Getting Job (%) |\n",
            "| --- | --- |\n",
            "| Data Scientist | 80% |\n",
            "| Data Analyst | 70% |\n",
            "| Business Analyst | 60% |\n",
            "\n",
            "**Recommendations:**\n",
            "\n",
            "* Improve skills in Natural Language Processing (NLP) and Deep Learning to increase chances of getting a job as a Data Scientist.\n",
            "* Develop skills in data storytelling and presentation to increase chances of getting a job as a Business Analyst.\n",
            "* Consider learning R programming language to increase chances of getting a job as a Data Analyst.\n",
            "\n",
            "**Easy to Apply Job Profiles:**\n",
            "\n",
            "| Job Profile | Matching Skills |\n",
            "| --- | --- |\n",
            "| Data Analyst | Python, Data Visualization, Database |\n",
            "| Business Analyst | Data Analysis, Data Visualization, Communication Skills |\n",
            "| Data Scientist | Machine Learning, Deep Learning, Python |\n",
            "\n",
            "**Additional Recommendations:**\n",
            "\n",
            "* Consider taking online courses to improve skills in NLP and Deep Learning.\n",
            "* Develop a personal project that showcases skills in data storytelling and presentation.\n",
            "* Network with professionals in the industry to increase chances of getting a job.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def display_markdown_in_colab(md_text):\n",
        "    display(Markdown(md_text))\n",
        "\n",
        "# Example markdown content\n",
        "\n",
        "display_markdown_in_colab(res2.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "collapsed": true,
        "id": "8CAKmFcbVOZb",
        "outputId": "717f5891-cf82-41f8-a212-47e309af57f0"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Resume Summary: Shiva Kumarr Thimmaraveni**\n\n**Summary:**\nShiva Kumarr Thimmaraveni is a 25-year-old Data Science enthusiast with a strong background in Electrical & Electronics Engineering and Computer Applications. He has 2 years of experience in developing end-to-end enterprise applications, chatbots, and data analysis. He has expertise in programming languages such as Python, JavaScript, and has experience with various frameworks and tools like GCP, Tableau, and Power BI.\n\n**Technical Skills:**\n\n* Programming Languages: Python (Pandas, NumPy, Matplotlib, Seaborn, ScikitLearn, SciPy, os), JavaScript\n* Machine Learning: Regression, Classification, Clustering, Association Rule Learning, Reinforcement Learning\n* Deep Learning: ANNs, CNNs, NLP\n* Web Development: HTML5, CSS3, JavaScript, Bootstrap, Tailwind CSS, React JS (Basics)\n* Data Visualization: Tableau, Excel, Power BI (Basics)\n* Database: PostgreSQL, MySQL\n* Cloud Service Providers: GCP ACE (Google Certified Associate Cloud Engineer)\n\n**Professional Experience:**\n\n* Developer at Client Avery Dennison - India (Remote) (June 2023 - July 2024)\n* Google Developer at Client C&S - India (Remote) (July 2022 - December 2022)\n\n**Projects:**\n\n* BCG Data Science Job Simulation on Forage - Certificate (July 2024)\n* Salary prediction on Given Experience - Personal Project (February 2024)\n* Profit Estimation of Startup on Given Spends - Personal Project (March 2024)\n\n**Education:**\n\n* Bachelor of Technology in Electrical & Electronics Engineering from Sri Indu Institutions (Affiliated to Jawaharlal Nehru Technological University) (June 2021)\n* Diploma in Computer Applications (DCA) (June 2015)\n\n**Job Profile Analysis:**\n\n| Job Profile | Chance of Getting Job (%) |\n| --- | --- |\n| Data Scientist | 80% |\n| Data Analyst | 70% |\n| Business Analyst | 60% |\n\n**Recommendations:**\n\n* Improve skills in Natural Language Processing (NLP) and Deep Learning to increase chances of getting a job as a Data Scientist.\n* Develop skills in data storytelling and presentation to increase chances of getting a job as a Business Analyst.\n* Consider learning R programming language to increase chances of getting a job as a Data Analyst.\n\n**Easy to Apply Job Profiles:**\n\n| Job Profile | Matching Skills |\n| --- | --- |\n| Data Analyst | Python, Data Visualization, Database |\n| Business Analyst | Data Analysis, Data Visualization, Communication Skills |\n| Data Scientist | Machine Learning, Deep Learning, Python |\n\n**Additional Recommendations:**\n\n* Consider taking online courses to improve skills in NLP and Deep Learning.\n* Develop a personal project that showcases skills in data storytelling and presentation.\n* Network with professionals in the industry to increase chances of getting a job."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import markdown\n",
        "from weasyprint import HTML\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "def markdown_to_pdf(markdown_text, output_filename='output.pdf'):\n",
        "    # Convert Markdown to HTML\n",
        "    html = markdown.markdown(markdown_text)\n",
        "\n",
        "    # Convert HTML to PDF\n",
        "    pdf = HTML(string=html).write_pdf()\n",
        "\n",
        "    # Save the PDF to a file\n",
        "    with open(output_filename, 'wb') as f:\n",
        "        f.write(pdf)\n",
        "\n",
        "    # Download the file\n",
        "    files.download(output_filename)\n",
        "\n",
        "# Example usage\n",
        "markdown_text = res.content\n",
        "\n",
        "markdown_to_pdf(markdown_text)\n",
        "\n",
        "# Interactive input\n",
        "user_markdown = input(\"Enter your Markdown text (press Enter twice when done):\\n\")\n",
        "while True:\n",
        "    line = input()\n",
        "    if line == \"\":\n",
        "        break\n",
        "    user_markdown += \"\\n\" + line\n",
        "\n",
        "markdown_to_pdf(user_markdown, 'user_output.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "3lz7NesxcINt",
        "outputId": "4b54aee6-03dc-455c-8b63-6c4b941bb3ea"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f93fd3d3-895e-4065-8c66-0592a41f2c47\", \"output.pdf\", 18383)"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Markdown text (press Enter twice when done):\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a92e27a0-456a-46ce-baec-98b3c5d792c1\", \"user_output.pdf\", 651)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import markdown\n",
        "from weasyprint import HTML, CSS\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "def markdown_to_pdf(markdown_text, output_filename='output.pdf'):\n",
        "    # Convert Markdown to HTML\n",
        "    html = markdown.markdown(markdown_text)\n",
        "\n",
        "    # Define CSS styles\n",
        "    css = CSS(string='''\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            line-height: 1.6;\n",
        "            color: #333;\n",
        "            max-width: 800px;\n",
        "            margin: 0 auto;\n",
        "            padding: 20px;\n",
        "        }\n",
        "        h1, h2, h3, h4, h5, h6 {\n",
        "            color: #2c3e50;\n",
        "            margin-top: 24px;\n",
        "            margin-bottom: 16px;\n",
        "        }\n",
        "        h1 {\n",
        "            border-bottom: 1px solid #eaecef;\n",
        "            padding-bottom: 0.3em;\n",
        "        }\n",
        "        a {\n",
        "            color: #0366d6;\n",
        "            text-decoration: none;\n",
        "        }\n",
        "        pre {\n",
        "            background-color: #f6f8fa;\n",
        "            border-radius: 3px;\n",
        "            padding: 16px;\n",
        "            overflow: auto;\n",
        "        }\n",
        "        code {\n",
        "            background-color: rgba(27,31,35,.05);\n",
        "            border-radius: 3px;\n",
        "            padding: 0.2em 0.4em;\n",
        "            font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;\n",
        "        }\n",
        "        blockquote {\n",
        "            border-left: 0.25em solid #dfe2e5;\n",
        "            color: #6a737d;\n",
        "            padding: 0 1em;\n",
        "        }\n",
        "        table {\n",
        "            border-collapse: collapse;\n",
        "            width: 100%;\n",
        "        }\n",
        "        th, td {\n",
        "            border: 1px solid #dfe2e5;\n",
        "            padding: 6px 13px;\n",
        "        }\n",
        "        tr:nth-child(even) {\n",
        "            background-color: #f6f8fa;\n",
        "        }\n",
        "    ''')\n",
        "\n",
        "    # Wrap the HTML content in a basic structure\n",
        "    full_html = f'''\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\">\n",
        "    </head>\n",
        "    <body>\n",
        "        {html}\n",
        "    </body>\n",
        "    </html>\n",
        "    '''\n",
        "\n",
        "    # Convert HTML to PDF with CSS\n",
        "    pdf = HTML(string=full_html).write_pdf(stylesheets=[css])\n",
        "\n",
        "    # Save the PDF to a file\n",
        "    with open(output_filename, 'wb') as f:\n",
        "        f.write(pdf)\n",
        "\n",
        "    # Download the file\n",
        "    files.download(output_filename)\n",
        "\n",
        "# Example usage\n",
        "markdown_text = res.content\n",
        "\n",
        "markdown_to_pdf(markdown_text)\n",
        "\n",
        "# Interactive input\n",
        "# user_markdown = input(\"Enter your Markdown text (press Enter twice when done):\\n\")\n",
        "# while True:\n",
        "#     line = input()\n",
        "#     if line == \"\":\n",
        "#         break\n",
        "#     user_markdown += \"\\n\" + line\n",
        "\n",
        "markdown_to_pdf(res.content,'user_output.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AGd3mqYPfeCO",
        "outputId": "9d61baef-9fcf-4948-e4f4-3a51ec932d09"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_284c2e95-db44-4905-88c3-2f42041f8943\", \"output.pdf\", 18347)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c8646d44-b086-48c6-a787-3f9fc76631dd\", \"user_output.pdf\", 18347)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def markdown_to_pdf(markdown_text, output_filename='output.pdf'):\n",
        "    # Convert Markdown to HTML\n",
        "    html = markdown.markdown(markdown_text, extensions=['tables'])\n",
        "\n",
        "    # Define CSS styles\n",
        "    css = CSS(string='''\n",
        "        @page {\n",
        "            size: A4;\n",
        "            margin: 1.5cm;\n",
        "        }\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            font-size: 10pt;\n",
        "            line-height: 1.3;\n",
        "            color: #333;\n",
        "        }\n",
        "        h1, h2, h3, h4, h5, h6 {\n",
        "            color: #2c3e50;\n",
        "            margin-top: 0.5em;\n",
        "            margin-bottom: 0.2em;\n",
        "        }\n",
        "        h1 {\n",
        "            font-size: 18pt;\n",
        "            border-bottom: 1px solid #eaecef;\n",
        "            padding-bottom: 0.3em;\n",
        "        }\n",
        "        h2 { font-size: 16pt; }\n",
        "        h3 { font-size: 14pt; }\n",
        "        h4, h5, h6 { font-size: 12pt; }\n",
        "        p {\n",
        "            margin-top: 0.3em;\n",
        "            margin-bottom: 0.7em;\n",
        "        }\n",
        "        a {\n",
        "            color: #0366d6;\n",
        "            text-decoration: none;\n",
        "        }\n",
        "        pre {\n",
        "            background-color: #f6f8fa;\n",
        "            border-radius: 3px;\n",
        "            padding: 0.5em;\n",
        "            font-size: 9pt;\n",
        "            overflow: auto;\n",
        "            white-space: pre-wrap;\n",
        "            word-wrap: break-word;\n",
        "        }\n",
        "        code {\n",
        "            background-color: rgba(27,31,35,.05);\n",
        "            border-radius: 3px;\n",
        "            padding: 0.2em 0.4em;\n",
        "            font-family: Consolas, monospace;\n",
        "            font-size: 9pt;\n",
        "        }\n",
        "        blockquote {\n",
        "            border-left: 3px solid #dfe2e5;\n",
        "            color: #6a737d;\n",
        "            padding-left: 0.5em;\n",
        "            margin-left: 0;\n",
        "        }\n",
        "        table {\n",
        "            border-collapse: collapse;\n",
        "            width: 100%;\n",
        "            margin-top: 0.5em;\n",
        "            margin-bottom: 1em;\n",
        "        }\n",
        "        th, td {\n",
        "            border: 1px solid #dfe2e5;\n",
        "            padding: 8px 12px;\n",
        "            text-align: left;\n",
        "            vertical-align: top;\n",
        "        }\n",
        "        th {\n",
        "            background-color: #f6f8fa;\n",
        "            font-weight: bold;\n",
        "            color: #24292e;\n",
        "        }\n",
        "        tr:nth-child(even) {\n",
        "            background-color: #f8f8f8;\n",
        "        }\n",
        "        tr:hover {\n",
        "            background-color: #f1f1f1;\n",
        "        }\n",
        "        img {\n",
        "            max-width: 100%;\n",
        "            height: auto;\n",
        "        }\n",
        "        ul, ol {\n",
        "            padding-left: 1.5em;\n",
        "            margin-top: 0.3em;\n",
        "            margin-bottom: 0.7em;\n",
        "        }\n",
        "    ''')\n",
        "\n",
        "    # Wrap the HTML content in a basic structure\n",
        "    full_html = f'''\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\">\n",
        "    </head>\n",
        "    <body>\n",
        "        {html}\n",
        "    </body>\n",
        "    </html>\n",
        "    '''\n",
        "\n",
        "    # Convert HTML to PDF with CSS\n",
        "    pdf = HTML(string=full_html).write_pdf(stylesheets=[css])\n",
        "\n",
        "    # Save the PDF to a file\n",
        "    with open(output_filename, 'wb') as f:\n",
        "        f.write(pdf)\n",
        "\n",
        "    # Download the file\n",
        "    files.download(output_filename)\n",
        "\n",
        "# Example usage\n",
        "markdown_text = res2.content\n",
        "\n",
        "markdown_to_pdf(markdown_text, 'user_output.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zOBKMlXEhpkY",
        "outputId": "cd259094-dec2-487a-854f-2edf390d63b4"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb486c53-8c75-413f-8ae6-91fc50cc8ca7\", \"user_output.pdf\", 16227)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}